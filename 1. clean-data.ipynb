{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12b8a9a7",
   "metadata": {},
   "source": [
    "# Part 1. clean data\n",
    "here we will clean the text data and encode the audio. and save both in disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97f1bbf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/talha/venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53358c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48827\n"
     ]
    }
   ],
   "source": [
    "train_df=pd.read_csv('csv/train_data.csv')\n",
    "train_df.drop_duplicates(inplace=True)\n",
    "print(len(train_df))\n",
    "#dataframe should have two columns, text and audio path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "908e4ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3298\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>text</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/commonvoice/clips/common_voice_ur_2897662...</td>\n",
       "      <td>یہی تناسب \"یوتھ\" کا بھی ہے۔</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/commonvoice/clips/common_voice_ur_3109379...</td>\n",
       "      <td>آئی ایم ایف کے ساتھ کن شرائط پر بات ہو رہی ہے؟</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/commonvoice/clips/common_voice_ur_3109379...</td>\n",
       "      <td>اور پھر سپاہی سے کہا \"ارے ہاں۔</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/commonvoice/clips/common_voice_ur_3201441...</td>\n",
       "      <td>اب صرف اور صرف انتظار ہے اگلے ماہ</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/commonvoice/clips/common_voice_ur_3203519...</td>\n",
       "      <td>تو میں پی ٹی وی میں اینکر تھا۔</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  \\\n",
       "0  data/commonvoice/clips/common_voice_ur_2897662...   \n",
       "1  data/commonvoice/clips/common_voice_ur_3109379...   \n",
       "2  data/commonvoice/clips/common_voice_ur_3109379...   \n",
       "3  data/commonvoice/clips/common_voice_ur_3201441...   \n",
       "4  data/commonvoice/clips/common_voice_ur_3203519...   \n",
       "\n",
       "                                             text  duration  \n",
       "0                     یہی تناسب \"یوتھ\" کا بھی ہے۔       2.8  \n",
       "1  آئی ایم ایف کے ساتھ کن شرائط پر بات ہو رہی ہے؟       4.9  \n",
       "2                  اور پھر سپاہی سے کہا \"ارے ہاں۔       4.0  \n",
       "3               اب صرف اور صرف انتظار ہے اگلے ماہ       3.6  \n",
       "4                  تو میں پی ٹی وی میں اینکر تھا۔       3.1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df=pd.read_csv('csv/test_data.csv')\n",
    "test_df.drop_duplicates(inplace=True)\n",
    "print(len(test_df))\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d59a4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfaa06e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=datasets.Dataset.from_pandas(test_df)\n",
    "train_data=datasets.Dataset.from_pandas(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c889ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'path', 'duration', '__index_level_0__'],\n",
       "        num_rows: 48827\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['path', 'text', 'duration', '__index_level_0__'],\n",
       "        num_rows: 3298\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urdata = datasets.DatasetDict({\n",
    "    'train': train_data,\n",
    "    'test':test_data})\n",
    "urdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3120e2b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-13 17:04:53.902357: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "100%|██████████████████████████████████| 48827/48827 [00:03<00:00, 13209.55ex/s]\n",
      "100%|████████████████████████████████████| 3298/3298 [00:00<00:00, 15210.47ex/s]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "from urduhack.normalization import *\n",
    "from urduhack.preprocessing import *\n",
    "chars_to_ignore_regex = \"\"\"[\\!\\؛\\،\\٫\\؟\\۔\\٪\\\"\\'\\:\\-\\‘\\’\\`]\"\"\"\n",
    "def clean_data(batch):\n",
    "    text=remove_punctuation(batch[\"text\"])\n",
    "    text=normalize_whitespace(text)\n",
    "    text=remove_accents(text)\n",
    "    text=normalize_characters(text)\n",
    "    text=normalize_combine_characters(text)\n",
    "    text=remove_diacritics(text)\n",
    "    text=normalize(text)\n",
    "#     text = re.sub('\\d+', '',text)\n",
    "    text = re.sub('[a-zA-Z]+', '',text)\n",
    "    text = re.sub('\\u200c', '',text)\n",
    "    text = re.sub('\\u200f', '',text)\n",
    "    text = re.sub('\\ufeff', '',text)\n",
    "    text = unicodedata.normalize(\"NFKC\", text)\n",
    "    text = re.sub(chars_to_ignore_regex, \"\", text)\n",
    "    #unify some character manually\n",
    "    text = re.sub('\\u0623','\\u0627',text)#أ\n",
    "    text = re.sub('\\u06C3', '\\u062A',text)#ه\n",
    "    text = re.sub('\\u0647', '\\u06C1',text)#ۃ\n",
    "    text = re.sub('\\u06C2', '\\u0621',text)#ۂ\n",
    "    text = re.sub('\\u0624', '\\u0648',text)#ؤ\n",
    "    text = re.sub('\\u06D3', '\\u06D2',text)#ۓ\n",
    "    text = re.sub('\\u0649', '\\u06cc',text)#ى\n",
    "    text = re.sub('\\u0626', '\\u06cc',text)#ئ\n",
    "    text = re.sub('\\u064a', '\\u06cc',text)#ي\n",
    "    return {\"text\":text }\n",
    "\n",
    "\n",
    "urdata=urdata.map(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48ffa509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48827"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "101fd450",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the cleaned text, will later used in language model\n",
    "text=[i['text'] for i in urdata['train']]\n",
    "pd.DataFrame(text,columns=['text']).to_csv('text4lm.csv',index=False)\n",
    "#will later use this test data text to evaluate our model \n",
    "text=[i['text'] for i in urdata['test']]\n",
    "pd.DataFrame(text,columns=['text']).to_csv('tex-test.csv',index=False)\n",
    "#both these files will be used in part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3cca1491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3298"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d97ce76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_chars(batch):\n",
    "  all_text = \" \".join(batch[\"text\"])\n",
    "  vocab = list(set(all_text))\n",
    "  return {\"vocab\": [vocab], \"all_text\": [all_text]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca36dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabs = urdata.map(extract_all_chars, batched=True, batch_size=-1, keep_in_memory=True, remove_columns=urdata.column_names[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32a3bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_list = list(set(vocabs[\"train\"][\"vocab\"][0]) | set(vocabs[\"test\"][\"vocab\"][0]))\n",
    "vocab_dict = {v: k for k, v in enumerate(vocab_list)}\n",
    "print(len(vocab_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab36c35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dict[\"|\"] = vocab_dict[\" \"]\n",
    "del vocab_dict[\" \"]\n",
    "vocab_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d746c29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8e5724",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dict[\"[UNK]\"] = len(vocab_dict)\n",
    "vocab_dict[\"[PAD]\"] = len(vocab_dict)\n",
    "print(len(vocab_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0307cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('vocab.json', 'w') as vocab_file:\n",
    "    json.dump(vocab_dict, vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df40d1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2CTCTokenizer\n",
    "tokenizer = Wav2Vec2CTCTokenizer(\"./cache/saved/vocab.json\", unk_token=\"[UNK]\", pad_token=\"[PAD]\", word_delimiter_token=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ab60ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2FeatureExtractor\n",
    "\n",
    "feature_extractor = Wav2Vec2FeatureExtractor(feature_size=1, sampling_rate=16000, padding_value=0.0, do_normalize=True, return_attention_mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc65d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2Processor\n",
    "\n",
    "processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fc9d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "urdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688e314c",
   "metadata": {},
   "outputs": [],
   "source": [
    "urdata['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0f2483",
   "metadata": {},
   "outputs": [],
   "source": [
    "urdata = urdata.cast_column(\"path\", datasets.Audio(sampling_rate=16_000))\n",
    "urdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5446f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "rand_int = random.randint(0, len(urdata['train'])-1)\n",
    "\n",
    "print(urdata['train'][rand_int][\"text\"])\n",
    "ipd.Audio(data=urdata['train'][rand_int][\"path\"][\"array\"], autoplay=True, rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8077bfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "urdata.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750315a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(batch):\n",
    "    audio = batch[\"path\"]\n",
    "    # batched output is \"un-batched\"\n",
    "    batch[\"input_values\"] = processor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_values[0]\n",
    "    batch[\"input_length\"] = len(batch[\"input_values\"])\n",
    "    \n",
    "    with processor.as_target_processor():\n",
    "        batch[\"labels\"] = processor(batch[\"text\"]).input_ids\n",
    "    return batch\n",
    "\n",
    "urdudata = urdata.map(prepare_dataset, remove_columns=urdata.column_names[\"train\"],num_proc=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11e054c",
   "metadata": {},
   "outputs": [],
   "source": [
    "urdudata.save_to_disk(\"cache/saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8701e060",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
