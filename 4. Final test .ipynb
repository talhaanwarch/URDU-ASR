{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95347cae",
   "metadata": {},
   "source": [
    "# Part 4. Test the word error rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4230d1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "from transformers import Wav2Vec2ProcessorWithLM\n",
    "import torch\n",
    "from jiwer import wer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "124eca8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "#our data in currently, in encoded formated\n",
    "#so i will use preporcessed features and clean text data\n",
    "urdudata = load_from_disk(\"cache/saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16000708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>یہی تناسب یوتھ کا بھی ہے</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>آیی ایم ایف کے ساتھ کن شرایط پر بات ہو رہی ہے</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>اور پھر سپاہی سے کہا ارے ہاں</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>اب صرف اور صرف انتظار ہے اگلے ماہ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>تو میں پی ٹی وی میں اینکر تھا</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            text\n",
       "0                       یہی تناسب یوتھ کا بھی ہے\n",
       "1  آیی ایم ایف کے ساتھ کن شرایط پر بات ہو رہی ہے\n",
       "2                   اور پھر سپاہی سے کہا ارے ہاں\n",
       "3              اب صرف اور صرف انتظار ہے اگلے ماہ\n",
       "4                  تو میں پی ٹی وی میں اینکر تھا"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text=pd.read_csv('tex-test.csv')\n",
    "test_text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9048ce39",
   "metadata": {},
   "source": [
    "# Without LM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32b46a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def map_to_pred(batch):\n",
    "    input_values = processor(batch[\"input_values\"], sampling_rate =16000,\n",
    "                             return_tensors=\"pt\", padding=\"longest\").input_values\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_values.to(\"cuda\")).logits\n",
    "    predicted_ids = torch.argmax(logits, dim=-1)\n",
    "    transcription = processor.batch_decode(predicted_ids)\n",
    "    batch[\"transcription\"] = transcription\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a6f200",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Wav2Vec2ForCTC.from_pretrained('urdumodel',local_files_only=True).to(\"cuda\")\n",
    "processor = Wav2Vec2Processor.from_pretrained('urdumodel',local_files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b040c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = urdudata['test'].map(map_to_pred, batched=True, batch_size=12, \n",
    "                              remove_columns=urdudata['test'].column_names)\n",
    "\n",
    "print(\"WER:\", wer(test_text['text'].to_list(), result[\"transcription\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdb930e",
   "metadata": {},
   "source": [
    "WER: 0.2720071796472608"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806056fe",
   "metadata": {},
   "source": [
    "# With Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666b66e8",
   "metadata": {},
   "source": [
    "#now here we need to remove some tokens, because our LM and vocaib tokens did not match  \n",
    "visit this link for info\n",
    "https://github.com/huggingface/transformers/issues/15392  \n",
    "perform following steps to fix this  \n",
    "\n",
    "### change special_tokens_map.json\n",
    "from \n",
    "```\n",
    "{\n",
    "  \"additional_special_tokens\": [\n",
    "    {\n",
    "      \"content\": \"<s>\",\n",
    "      \"lstrip\": false,\n",
    "      \"normalized\": true,\n",
    "      \"rstrip\": false,\n",
    "      \"single_word\": false\n",
    "    },\n",
    "    {\n",
    "      \"content\": \"</s>\",\n",
    "      \"lstrip\": false,\n",
    "      \"normalized\": true,\n",
    "      \"rstrip\": false,\n",
    "      \"single_word\": false\n",
    "    }\n",
    "  ],\n",
    "  \"bos_token\": \"<s>\",\n",
    "  \"eos_token\": \"</s>\",\n",
    "  \"pad_token\": \"[PAD]\",\n",
    "  \"unk_token\": \"[UNK]\"\n",
    "}\n",
    "```\n",
    "to\n",
    "```\n",
    "{\"bos_token\": null, \"eos_token\": null, \"unk_token\": \"<UNK>\", \"pad_token\": \"<PAD>\"}\n",
    "```\n",
    "### changes in tokenizer_config.json\n",
    "From \n",
    "```\n",
    "\"bos_token\": \"<s>\",\n",
    "\"eos_token\": \"</s>\",\n",
    "```\n",
    "To\n",
    "```\n",
    "\"bos_token\": null,\n",
    "\"eos_token\": null,\n",
    "```\n",
    "Dont remove other lines\n",
    "\n",
    "### changes in added_tokens.json\n",
    "From\n",
    "```\n",
    "{\"<s>\": 48, \"</s>\": 49}\n",
    "```\n",
    "To\n",
    "`{}`\n",
    "\n",
    "### Chnages in  alphabet.json\n",
    "Remove these two ```\"<s>\", \"</s>\"```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5209ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_pred(batch):\n",
    "    input_values = processor(batch[\"input_values\"], sampling_rate =16000,\n",
    "                             return_tensors=\"pt\", padding=\"longest\").input_values\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_values.to(\"cuda\")).logits\n",
    "    predicted_ids = torch.argmax(logits, dim=-2)\n",
    "    transcription = processor.batch_decode(logits.cpu().numpy()).text\n",
    "    batch[\"transcription\"] = transcription\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc9c0307",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model = Wav2Vec2ForCTC.from_pretrained('urdumodellm',local_files_only=True).to(\"cuda\")\n",
    "processor = Wav2Vec2ProcessorWithLM.from_pretrained(\"urdumodellm\",local_files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bb2b21a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58e61eb548784ef59a4abf1a0561d411",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/275 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-13 18:34:17.133532: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER: 0.22007179647260808\n"
     ]
    }
   ],
   "source": [
    "result = urdudata['test'].map(map_to_pred, batched=True, batch_size=12, \n",
    "                              remove_columns=urdudata['test'].column_names)\n",
    "\n",
    "print(\"WER:\", wer(test_text['text'].to_list(), result[\"transcription\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80e68ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
